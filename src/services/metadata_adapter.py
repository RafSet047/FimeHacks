"""
Metadata Adapter for bridging between different metadata structures
"""

from typing import Dict, Any, List, Optional
import time
import logging

logger = logging.getLogger(__name__)


class MetadataAdapter:
    """Bridge between different metadata structures in the processing pipeline"""
    
    @staticmethod
    def simple_to_enhanced(
        simple_metadata: Dict[str, Any], 
        ai_tags: List[str],
        chunk_info: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Convert simple metadata + AI tags to enhanced metadata for storage
        
        Args:
            simple_metadata: Basic metadata from user input
            ai_tags: Tags generated by StoreAgent
            chunk_info: Optional chunk-specific information
            
        Returns:
            Enhanced metadata dictionary for vector storage
        """
        try:
            enhanced_metadata = {
                # Original user metadata
                "filename": simple_metadata.get("filename", ""),
                "department": simple_metadata.get("department", "general"),
                "description": simple_metadata.get("description", ""),
                "user_tags": simple_metadata.get("tags", []),
                "project": simple_metadata.get("project", ""),
                
                # AI-generated metadata
                "ai_tags": ai_tags,
                "ai_analysis_timestamp": time.time(),
                "agent_name": "StoreAgent",
                
                # Combined tags for search
                "tags": simple_metadata.get("tags", []) + ai_tags,
                
                # Chunk information
                "chunk_info": chunk_info or {},
                
                # Organizational metadata
                "organizational": {
                    "role": simple_metadata.get("employee_role", "user"),
                    "organization_type": simple_metadata.get("organization_type", "university"),
                    "security_level": simple_metadata.get("access_level", "internal")
                },
                
                # Processing metadata
                "processing_timestamp": time.time(),
                "content_length": simple_metadata.get("content_length", 0),
                "processing_version": "1.0"
            }
            
            return enhanced_metadata
            
        except Exception as e:
            logger.error(f"Error creating enhanced metadata: {e}")
            # Return minimal metadata as fallback
            return {
                "filename": simple_metadata.get("filename", "unknown"),
                "department": simple_metadata.get("department", "general"),
                "ai_tags": ai_tags,
                "tags": ai_tags,
                "organizational": {
                    "role": "user",
                    "organization_type": "university",
                    "security_level": "internal"
                },
                "processing_timestamp": time.time(),
                "error": "metadata_processing_failed"
            }
    
    @staticmethod
    def prepare_chunk_metadata(
        base_metadata: Dict[str, Any],
        chunk_text: str,
        chunk_index: int,
        total_chunks: int
    ) -> Dict[str, Any]:
        """
        Prepare chunk-specific metadata
        
        Args:
            base_metadata: Base metadata from document
            chunk_text: Text content of the chunk
            chunk_index: Index of current chunk
            total_chunks: Total number of chunks
            
        Returns:
            Chunk-specific metadata
        """
        try:
            chunk_metadata = {
                **base_metadata,
                "chunk_index": chunk_index,
                "total_chunks": total_chunks,
                "chunk_text_preview": chunk_text[:200] + "..." if len(chunk_text) > 200 else chunk_text,
                "chunk_length": len(chunk_text),
                "chunk_word_count": len(chunk_text.split()),
                "is_first_chunk": chunk_index == 0,
                "is_last_chunk": chunk_index == total_chunks - 1
            }
            
            return chunk_metadata
            
        except Exception as e:
            logger.error(f"Error preparing chunk metadata: {e}")
            return {
                **base_metadata,
                "chunk_index": chunk_index,
                "total_chunks": total_chunks,
                "error": "chunk_metadata_failed"
            }
    
    @staticmethod
    def extract_search_metadata(enhanced_metadata: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extract key metadata for search operations
        
        Args:
            enhanced_metadata: Full enhanced metadata
            
        Returns:
            Simplified metadata for search
        """
        try:
            return {
                "filename": enhanced_metadata.get("filename", ""),
                "department": enhanced_metadata.get("department", "general"),
                "all_tags": enhanced_metadata.get("tags", []),
                "ai_tags": enhanced_metadata.get("ai_tags", []),
                "user_tags": enhanced_metadata.get("user_tags", []),
                "chunk_index": enhanced_metadata.get("chunk_index", 0),
                "organization_type": enhanced_metadata.get("organizational", {}).get("organization_type", "university"),
                "content_preview": enhanced_metadata.get("chunk_text_preview", ""),
                "processing_timestamp": enhanced_metadata.get("processing_timestamp", 0)
            }
            
        except Exception as e:
            logger.error(f"Error extracting search metadata: {e}")
            return {
                "filename": "unknown",
                "department": "general",
                "all_tags": [],
                "error": "search_metadata_failed"
            }
    
    @staticmethod
    def validate_metadata(metadata: Dict[str, Any]) -> bool:
        """
        Validate metadata structure
        
        Args:
            metadata: Metadata to validate
            
        Returns:
            True if valid, False otherwise
        """
        try:
            required_fields = ["filename", "department", "tags"]
            
            for field in required_fields:
                if field not in metadata:
                    logger.warning(f"Missing required field: {field}")
                    return False
            
            # Validate tags is a list
            if not isinstance(metadata.get("tags"), list):
                logger.warning("Tags field must be a list")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"Error validating metadata: {e}")
            return False 